{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CV with:\n",
    "  - Linear Regression\n",
    "  - Decision Tree classification\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Generalized Error on Linear Regression with K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data set\n",
    "[Data Set](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.015491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044528</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081414</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  \n",
       "0   -0.002592  0.019908 -0.017646  \n",
       "1   -0.039493 -0.068330 -0.092204  \n",
       "2   -0.002592  0.002864 -0.025930  \n",
       "3    0.034309  0.022692 -0.009362  \n",
       "4   -0.002592 -0.031991 -0.046641  \n",
       "..        ...       ...       ...  \n",
       "437 -0.002592  0.031193  0.007207  \n",
       "438  0.034309 -0.018118  0.044485  \n",
       "439 -0.011080 -0.046879  0.015491  \n",
       "440  0.026560  0.044528 -0.025930  \n",
       "441 -0.039493 -0.004220  0.003064  \n",
       "\n",
       "[442 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X = load_diabetes(as_frame = True)['data']\n",
    "s_y = load_diabetes(as_frame = True)['target']\n",
    "df_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear least squares regression model function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns LSR Model\n",
    "def get_linear_regression_model( df_X, s_y ):\n",
    "    ones = pd.DataFrame({'intercept': np.ones(len(df_X))})\n",
    "    df_X = ones.join(df_X)\n",
    "    return np.linalg.lstsq(df_X, s_y, rcond = -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.18818425,  1.77890808,  0.74032569, -1.3506416 ,  0.14535984])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check beta_hat\n",
    "np.random.seed(23)\n",
    "beta_hat = get_linear_regression_model( pd.DataFrame(np.random.random((34,4))), pd.Series(np.random.random(34)*10.0) )\n",
    "beta_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns fold dictionaries: partitions = ({1: sub-df, 2: sub-df ...}, {1: sub-s, 2: sub-s ...})\n",
    "def partition_data( df_X, s_y, k ):\n",
    "    partitions = ({}, {})\n",
    "    df = df_X.join(s_y).sample(frac = 1)\n",
    "    arrays = np.array_split(df, k)\n",
    "    for i in range(1, k + 1):\n",
    "        partitions[0][i] = arrays[i - 1].iloc[:, :-1]\n",
    "        partitions[1][i] = arrays[i - 1].iloc[:, -1:]\n",
    "    return partitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>-0.041840</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.053630</td>\n",
       "      <td>-0.040099</td>\n",
       "      <td>-0.084126</td>\n",
       "      <td>-0.071772</td>\n",
       "      <td>-0.002903</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.072128</td>\n",
       "      <td>-0.030072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-0.052738</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.054152</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.055231</td>\n",
       "      <td>-0.033881</td>\n",
       "      <td>-0.013948</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.074089</td>\n",
       "      <td>-0.059067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-0.012780</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.065486</td>\n",
       "      <td>-0.069938</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.016849</td>\n",
       "      <td>-0.002903</td>\n",
       "      <td>-0.007020</td>\n",
       "      <td>-0.030751</td>\n",
       "      <td>-0.050783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.085430</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.022373</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.026366</td>\n",
       "      <td>0.015505</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.072128</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.019913</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>0.045972</td>\n",
       "      <td>-0.018080</td>\n",
       "      <td>-0.054549</td>\n",
       "      <td>0.063367</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>0.028661</td>\n",
       "      <td>0.061054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.001895</td>\n",
       "      <td>0.008101</td>\n",
       "      <td>-0.004321</td>\n",
       "      <td>-0.015719</td>\n",
       "      <td>-0.002903</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.038393</td>\n",
       "      <td>-0.013504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.019913</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.040696</td>\n",
       "      <td>-0.015999</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.017598</td>\n",
       "      <td>0.052322</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.030751</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.067136</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.025607</td>\n",
       "      <td>-0.040099</td>\n",
       "      <td>-0.063487</td>\n",
       "      <td>-0.059873</td>\n",
       "      <td>-0.002903</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.019197</td>\n",
       "      <td>0.011349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>-0.060003</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>-0.029771</td>\n",
       "      <td>-0.007073</td>\n",
       "      <td>-0.021669</td>\n",
       "      <td>0.011824</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031815</td>\n",
       "      <td>-0.054925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>-0.041840</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.033151</td>\n",
       "      <td>-0.022885</td>\n",
       "      <td>0.046589</td>\n",
       "      <td>0.041587</td>\n",
       "      <td>0.056003</td>\n",
       "      <td>-0.024733</td>\n",
       "      <td>-0.025952</td>\n",
       "      <td>-0.038357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "133 -0.041840  0.050680 -0.053630 -0.040099 -0.084126 -0.071772 -0.002903   \n",
       "198 -0.052738 -0.044642  0.054152 -0.026328 -0.055231 -0.033881 -0.013948   \n",
       "158 -0.012780 -0.044642 -0.065486 -0.069938  0.001183  0.016849 -0.002903   \n",
       "21  -0.085430  0.050680 -0.022373  0.001215 -0.037344 -0.026366  0.015505   \n",
       "319  0.019913 -0.044642  0.004572  0.045972 -0.018080 -0.054549  0.063367   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "13   0.005383  0.050680 -0.001895  0.008101 -0.004321 -0.015719 -0.002903   \n",
       "386  0.019913 -0.044642 -0.040696 -0.015999 -0.008449 -0.017598  0.052322   \n",
       "64   0.067136  0.050680 -0.025607 -0.040099 -0.063487 -0.059873 -0.002903   \n",
       "395 -0.060003 -0.044642  0.001339 -0.029771 -0.007073 -0.021669  0.011824   \n",
       "429 -0.041840 -0.044642 -0.033151 -0.022885  0.046589  0.041587  0.056003   \n",
       "\n",
       "           s4        s5        s6  \n",
       "133 -0.039493 -0.072128 -0.030072  \n",
       "198 -0.039493 -0.074089 -0.059067  \n",
       "158 -0.007020 -0.030751 -0.050783  \n",
       "21  -0.039493 -0.072128 -0.017646  \n",
       "319 -0.039493  0.028661  0.061054  \n",
       "..        ...       ...       ...  \n",
       "13  -0.002592  0.038393 -0.013504  \n",
       "386 -0.039493 -0.030751  0.003064  \n",
       "64  -0.039493 -0.019197  0.011349  \n",
       "395 -0.002592  0.031815 -0.054925  \n",
       "429 -0.024733 -0.025952 -0.038357  \n",
       "\n",
       "[89 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dict_k_df_X, dict_k_s_y) = partition_data( df_X, s_y, 5 )\n",
    "dict_k_df_X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: df_X length = 89 and s_y = 89\n",
      "Fold 2: df_X length = 89 and s_y = 89\n",
      "Fold 3: df_X length = 88 and s_y = 88\n",
      "Fold 4: df_X length = 88 and s_y = 88\n",
      "Fold 5: df_X length = 88 and s_y = 88\n",
      "The sum of the number of elements in each fold is 442 and there are 442 rows in the original df\n"
     ]
    }
   ],
   "source": [
    "# Check fold sizes\n",
    "sum = 0\n",
    "for i in dict_k_df_X:\n",
    "    print(f'Fold {i}: df_X length = {len(dict_k_df_X[i])} and s_y = {len(dict_k_df_X[i])}')\n",
    "    sum += len(dict_k_df_X[i])\n",
    "print(f'The sum of the number of elements in each fold is {sum} and there are {len(df_X)} rows in the original df' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE function\n",
    "$MAE = \\sum\\limits_{i=1}^n\\frac{|{s\\_y_i - {s\\_y\\_hat}_i}|}{n}$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(s_y, s_y_hat):\n",
    "    mae = 0\n",
    "    n = len(s_y)\n",
    "    for i in range(n):\n",
    "        mae += abs(s_y[i] - s_y_hat[i])\n",
    "    return float(mae / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test \n",
    "x = np.array([1,2,3])\n",
    "y = np.array([2,2,3])\n",
    "get_mae(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get $MAE$ for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41.87109201, 42.88369483, 43.73687201, 46.46223755, 47.02704001])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = np.array([])\n",
    "for k in dict_k_df_X.keys():\n",
    "    # Concat training arrays\n",
    "    train_X = pd.DataFrame(np.concatenate([v for (n, v) in dict_k_df_X.items() if n != k]))\n",
    "    train_y = pd.DataFrame(np.concatenate([v for (n, v) in dict_k_s_y.items() if n != k]))\n",
    "    # Get beta_hat from training arrays\n",
    "    beta_hat = get_linear_regression_model(train_X, train_y)\n",
    "    # Add intercept col to test_X\n",
    "    test_X = dict_k_df_X[k].reset_index(drop = True)\n",
    "    test_X = pd.DataFrame({'intercept': np.ones(len(test_X))}).join(test_X)\n",
    "    # Get s_y_hat from test set\n",
    "    s_y_hat = np.matmul(np.array(test_X), np.array(beta_hat))\n",
    "    # Calc mae using s_y (with reset index) and s_y_hat\n",
    "    s_y = np.array(dict_k_s_y[k].reset_index(drop = True))\n",
    "    mae = np.append(mae, get_mae(s_y, s_y_hat))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min MAE is 41.87, the max MAE is 47.03, and the mean MAE is 44.40\n"
     ]
    }
   ],
   "source": [
    "print(\"The min MAE is {:.2f}, the max MAE is {:.2f}, and the mean MAE is {:.2f}\".format(mae.min(),mae.max(),mae.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Find the best Decision Tree hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load iris data\n",
    "[Data](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = load_iris(as_frame = True)['data']\n",
    "s_y = load_iris(as_frame = True)['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition `df_X` and `s_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: df_X length = 30 and s_y = 30\n",
      "Fold 2: df_X length = 30 and s_y = 30\n",
      "Fold 3: df_X length = 30 and s_y = 30\n",
      "Fold 4: df_X length = 30 and s_y = 30\n",
      "Fold 5: df_X length = 30 and s_y = 30\n",
      "The sum of the number of elements in each fold is 150 and there are 150 rows in the original df\n"
     ]
    }
   ],
   "source": [
    "(dict_k_df_X, dict_k_s_y) = partition_data(df_X, s_y, 5)\n",
    "sum = 0\n",
    "for i in dict_k_df_X:\n",
    "    print(f'Fold {i}: df_X length = {len(dict_k_df_X[i])} and s_y = {len(dict_k_df_X[i])}')\n",
    "    sum += len(dict_k_df_X[i])\n",
    "print(f'The sum of the number of elements in each fold is {sum} and there are {len(df_X)} rows in the original df' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(s_1, s_2):\n",
    "    j = len(s_1)\n",
    "    for i in range(len(s_1)):\n",
    "        if s_1[i] != s_2[i]:\n",
    "            j -= 1\n",
    "    return j / len(s_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acc(s_y,np.ones(len(s_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Nested Cross validation, find the best hyperparameter\n",
    "Using:\\\n",
    "[Decision Tree Classifier](https://scikit-learn.org/stable/modules/tree.html#classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing 0.1 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.94\n",
      "Testing 0.25 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.84\n",
      "Testing 0.3 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.63\n",
      "Testing 0.4 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.28\n",
      "\n",
      "Testing 0.1 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.95\n",
      "Testing 0.25 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.95\n",
      "Testing 0.3 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.64\n",
      "Testing 0.4 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.27\n",
      "\n",
      "Testing 0.1 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.93\n",
      "Testing 0.25 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.93\n",
      "Testing 0.3 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.58\n",
      "Testing 0.4 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.26\n",
      "\n",
      "Testing 0.1 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.93\n",
      "Testing 0.25 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.93\n",
      "Testing 0.3 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.61\n",
      "Testing 0.4 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.33\n",
      "\n",
      "Testing 0.1 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.93\n",
      "Testing 0.25 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.87\n",
      "Testing 0.3 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.69\n",
      "Testing 0.4 min impurity decrease\n",
      "    Average accuracy over 4 folds is 0.32\n"
     ]
    }
   ],
   "source": [
    "possible_min_impurity_decrease = np.array([0.1,0.25,0.3,0.4])\n",
    "\n",
    "# Outer loop\n",
    "outer_acc = np.array([])\n",
    "for k in dict_k_df_X.keys():\n",
    "    print()\n",
    "    train_partitions_X = [v for (n, v) in dict_k_df_X.items() if n != k]\n",
    "    train_partitions_y = [v for (n, v) in dict_k_s_y.items() if n != k]\n",
    "    # Choosing best m_i_d\n",
    "    max_acc = float('-inf')\n",
    "    min_decrease = float('inf')\n",
    "    \n",
    "    for pos_min_impurity in possible_min_impurity_decrease:\n",
    "        print(f'Testing {pos_min_impurity} min impurity decrease')\n",
    "        \n",
    "        # get average acc. for impurity measure\n",
    "        # Inner loop cross validation code here (use 4 folds, where the fold does not include k)\n",
    "        s = 0\n",
    "        for i in range(len(train_partitions_X)):\n",
    "            # Get mini train partitions\n",
    "            small_train_partition_X = np.concatenate([x for (idx, x) in enumerate(train_partitions_X) if idx != i])\n",
    "            small_train_partition_y = np.concatenate([y for (idx, y) in enumerate(train_partitions_y) if idx != i])\n",
    "            # Create and fit tree\n",
    "            clf = tree.DecisionTreeClassifier(min_impurity_decrease = pos_min_impurity)\n",
    "            clf.fit(small_train_partition_X, small_train_partition_y)\n",
    "            # Predict \n",
    "            small_y_hat = clf.predict(train_partitions_X[i])\n",
    "            # add accuracy to sum \n",
    "            \n",
    "            s += get_acc(np.array(train_partitions_y[i]), small_y_hat)\n",
    "\n",
    "        # get avg. acc. for m.i.d and set to min_acc if smaller\n",
    "        print(f'    Average accuracy over 4 folds is {round(s / (i + 1), 2)}')\n",
    "        if s / (i + 1) > max_acc:\n",
    "            max_acc = s / (i + 1)\n",
    "            min_decrease = pos_min_impurity\n",
    "            \n",
    "        elif s / i == max_acc and pos_min_impurity < min_decrease:\n",
    "            min_decrease = pos_min_impurity\n",
    "\n",
    "    # Use best min impurity decrease to train model\n",
    "    train_X = np.concatenate(train_partitions_X)\n",
    "    train_y = np.concatenate(train_partitions_y)\n",
    "    clf = tree.DecisionTreeClassifier(min_impurity_decrease = min_decrease)\n",
    "    clf.fit(train_X, train_y)\n",
    "    # Predict \n",
    "    y_hat = clf.predict(dict_k_df_X[k])\n",
    "    # Outer accuracy calculation\n",
    "    this_acc = get_acc(y_hat, np.array(dict_k_s_y[k]))\n",
    "    outer_acc = np.append(outer_acc, this_acc) # make sure and calculate this_acc in your loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized performance of classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum accuracy of the outer fold set is 0.8666666666666667.\n",
      "The maximum accuracy of the outer fold set is 0.9666666666666667.\n",
      "The mean accuracy of the outer fold set is 0.9333333333333333.\n"
     ]
    }
   ],
   "source": [
    "print(f'The minimum accuracy of the outer fold set is {outer_acc.min()}.')\n",
    "print(f'The maximum accuracy of the outer fold set is {outer_acc.max()}.')\n",
    "print(f'The mean accuracy of the outer fold set is {outer_acc.mean()}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
